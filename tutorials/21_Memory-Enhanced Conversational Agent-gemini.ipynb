{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5062797-0092-4d0c-b133-cb3557289cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv('GOOGLE_API_KEY')\n",
    "# Initialize the language model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8891e5b9-185d-4f8e-9001-f9243503f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Stores\n",
    "# We'll create stores for both short-term (chat history) and long-term memory.\n",
    "\n",
    "chat_store = {}\n",
    "long_term_memory = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in chat_store:\n",
    "        chat_store[session_id] = ChatMessageHistory()\n",
    "    return chat_store[session_id]\n",
    "\n",
    "def update_long_term_memory(session_id: str, input: str, output: str):\n",
    "    if session_id not in long_term_memory:\n",
    "        long_term_memory[session_id] = []\n",
    "    if len(input) > 20:  # Simple logic: store inputs longer than 20 characters\n",
    "        long_term_memory[session_id].append(f\"User said: {input}\")\n",
    "    if len(long_term_memory[session_id]) > 5:  # Keep only last 5 memories\n",
    "        long_term_memory[session_id] = long_term_memory[session_id][-5:]\n",
    "\n",
    "def get_long_term_memory(session_id: str):\n",
    "    return \". \".join(long_term_memory.get(session_id, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892aef1f-d8fa-4688-b950-d57ef2bb0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "# We'll create a prompt template that includes both short-term and long-term memory.\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Use the information from long-term memory if relevant.\"),\n",
    "    (\"system\", \"Long-term memory: {long_term_memory}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92796ea-3c20-4cea-8611-7013596af66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational Chain\n",
    "# Now, we'll set up the conversational chain with message history.\n",
    "\n",
    "chain = prompt | llm\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9d73a2-c54f-4d6e-b314-577271dd5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Function\n",
    "# We'll create a function to handle chat interactions, including updating long-term memory.\n",
    "\n",
    "def chat(input_text: str, session_id: str):\n",
    "    long_term_mem = get_long_term_memory(session_id)\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"input\": input_text, \"long_term_memory\": long_term_mem},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    update_long_term_memory(session_id, input_text, response.content)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ea57f8-c0e8-447b-b162-b30e775bf4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello Alice, it's nice to meet you! I'm glad to be able to assist you today.\n",
      "AI: I do not have real-time access to the internet, including weather information. To find out the weather, please check a reliable weather app or website.\n",
      "AI: Sunny days are great! What do you like to do on sunny days, Alice?\n",
      "AI: Yes, I remember your name is Alice.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "# Let's test our memory-enhanced conversational agent with a series of interactions.\n",
    "\n",
    "session_id = \"user_123\"\n",
    "\n",
    "print(\"AI:\", chat(\"Hello! My name is Alice.\", session_id))\n",
    "print(\"AI:\", chat(\"What's the weather like today?\", session_id))\n",
    "print(\"AI:\", chat(\"I love sunny days.\", session_id))\n",
    "print(\"AI:\", chat(\"Do you remember my name?\", session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b953e6db-b74f-44fc-9e37-46ec77ade903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation History:\n",
      "human: Hello! My name is Alice.\n",
      "ai: Hello Alice, it's nice to meet you! I'm glad to be able to assist you today.\n",
      "human: What's the weather like today?\n",
      "ai: I do not have real-time access to the internet, including weather information. To find out the weather, please check a reliable weather app or website.\n",
      "human: I love sunny days.\n",
      "ai: Sunny days are great! What do you like to do on sunny days, Alice?\n",
      "human: Do you remember my name?\n",
      "ai: Yes, I remember your name is Alice.\n",
      "\n",
      "Long-term Memory:\n",
      "User said: Hello! My name is Alice.. User said: What's the weather like today?. User said: Do you remember my name?\n"
     ]
    }
   ],
   "source": [
    "# Review Memory\n",
    "# Let's review the conversation history and long-term memory.\n",
    "\n",
    "print(\"Conversation History:\")\n",
    "for message in chat_store[session_id].messages:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n",
    "print(\"\\nLong-term Memory:\")\n",
    "print(get_long_term_memory(session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1c626-9a95-45f9-a55c-58b639c8eb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
